{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7555e190",
   "metadata": {},
   "source": [
    "# Scraping Financial Data of the Stocks from Screener.com\n",
    "\n",
    "TODO(Intro):\n",
    "\n",
    "- Importing the library for scraping data with python\n",
    "- The libraries we are going to use are BeautifulSoup, Pandas, Requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72118da7",
   "metadata": {},
   "source": [
    "Here are the Steps we will follow:\n",
    "- We are going to scape https://www.screener.in/explore/\n",
    "- We will get stock data  from all the sector (eg Chemical, Bank, Energy, Infrastructure etc...)\n",
    "- From each sector we will get the financial data of the list company(P/E ration, Book Value, 1year return etc..)\n",
    "- For each sector we will create a csv file to store the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede4461",
   "metadata": {},
   "source": [
    "## Scraping the list of sector from Screener in\n",
    "\n",
    "- use request to download the page\n",
    "- use Bs4 to prase and extract information\n",
    "- using pandas to convert it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9712df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the request from the website to fetch the data\n",
    "\n",
    "url = \"https://www.screener.in/explore/\"\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b783d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff83a84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using beautifulsoup to parse the data from the website\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee8294",
   "metadata": {},
   "source": [
    "![](https://imgur.com/aYqu5jb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a tags that contains the name and link to the financial data of the company\n",
    "\n",
    "selection_class = 'bordered radius-6 padding-4-12 font-size-14 ink-700'\n",
    "topic_title  = soup.find_all('a', {'class': selection_class})\n",
    "topic_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17859260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for  getting all the name of the sector\n",
    "\n",
    "topic_tag = []\n",
    "for tag in topic_title:\n",
    "    topic_tag.append(tag.text.replace('/',\"\").strip())\n",
    "topic_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for  getting all the link to the sectors financial data\n",
    "\n",
    "base = \"https://www.screener.in\"\n",
    "topic_url = []\n",
    "for tag in topic_title:\n",
    "    topic_url.append(base + tag['href'])\n",
    "    \n",
    "print(topic_url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c9ca881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agro Chemicals</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air Transport Service</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alcoholic Beverages</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Ancillaries</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Telecomm-Service</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Textiles</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Tobacco Products</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Trading</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Tyres</td>\n",
       "      <td>&lt;function topic_url at 0x0000016243154A60&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                         url\n",
       "0          Agro Chemicals  <function topic_url at 0x0000016243154A60>\n",
       "1   Air Transport Service  <function topic_url at 0x0000016243154A60>\n",
       "2     Alcoholic Beverages  <function topic_url at 0x0000016243154A60>\n",
       "3        Auto Ancillaries  <function topic_url at 0x0000016243154A60>\n",
       "4              Automobile  <function topic_url at 0x0000016243154A60>\n",
       "..                    ...                                         ...\n",
       "78       Telecomm-Service  <function topic_url at 0x0000016243154A60>\n",
       "79               Textiles  <function topic_url at 0x0000016243154A60>\n",
       "80       Tobacco Products  <function topic_url at 0x0000016243154A60>\n",
       "81                Trading  <function topic_url at 0x0000016243154A60>\n",
       "82                  Tyres  <function topic_url at 0x0000016243154A60>\n",
       "\n",
       "[83 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe from the scraped data\n",
    "\n",
    "market_data = {'title' : topic_tag, 'url': topic_url}\n",
    "market_df = pd.DataFrame(market_data)\n",
    "market_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dcc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craeting a csv file to store the data\n",
    "\n",
    "market_df.to_csv(r\"C:\\Users\\g\\Pictures\\Begining story of stock market\\market_analysis.csv\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf51a2",
   "metadata": {},
   "source": [
    "##  Now we have name of the each sector and link to the financial data\n",
    "\n",
    "- Now we are going scarpe data from the chemical sector and all the listed company financial data\n",
    "- Then we are going to make  a Dataframe out of it and going to save it to a csv file\n",
    "- After that we are going to create a function that will automatically get data from all the sector\n",
    "  and we are going to save all of them in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the request from the website and parsing the data\n",
    "\n",
    "topic_urls =  topic_url[23]\n",
    "topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(topic_urls)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff2d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6200a",
   "metadata": {},
   "source": [
    "![](https://imgur.com/MI9QD6O.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the heading of the table that content all the financial aspect of the company \n",
    "\n",
    "table = 'data-table text-nowrap striped mark-visited'\n",
    "table_tag = soup.find_all('table', {'class': table})\n",
    "table_tag[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tag =table_tag[0].find_all('tr')[0]\n",
    "tr_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6e4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_tag = tr_tag.find_all('a')\n",
    "n =a_tag[10]\n",
    "n.text[:30].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dce371",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = []\n",
    "for x in tr_tag.find_all('a'):\n",
    "    heading.append(x.text[:28].strip())\n",
    "    \n",
    "heading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e39d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the  table that content all the financial ratio of the company \n",
    "\n",
    "table_value = []\n",
    "for x in table_tag[0].find_all('tr')[1:]:\n",
    "    td_tags = x.find_all('td')\n",
    "    td_val = [y.text.strip() for y in td_tags]\n",
    "    table_value.append(td_val)\n",
    "    \n",
    "table_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "037824f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No.</th>\n",
       "      <th>Name</th>\n",
       "      <th>CMP</th>\n",
       "      <th>P/E</th>\n",
       "      <th>Mar Cap</th>\n",
       "      <th>Div Yld</th>\n",
       "      <th>NP Qtr</th>\n",
       "      <th>Qtr Profit Var</th>\n",
       "      <th>Sales Qtr</th>\n",
       "      <th>Qtr Sales Var</th>\n",
       "      <th>ROCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Info Edg.(India)</td>\n",
       "      <td>3657.05</td>\n",
       "      <td>15.88</td>\n",
       "      <td>47243.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>93.90</td>\n",
       "      <td>59.50</td>\n",
       "      <td>604.13</td>\n",
       "      <td>65.94</td>\n",
       "      <td>24.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Zomato Ltd</td>\n",
       "      <td>48.75</td>\n",
       "      <td></td>\n",
       "      <td>41698.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.80</td>\n",
       "      <td>103.27</td>\n",
       "      <td>1177.90</td>\n",
       "      <td>31.30</td>\n",
       "      <td>-10.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>FSN E-Commerce</td>\n",
       "      <td>141.75</td>\n",
       "      <td>914.42</td>\n",
       "      <td>40389.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.19</td>\n",
       "      <td>251.28</td>\n",
       "      <td>1230.83</td>\n",
       "      <td>39.04</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>One 97</td>\n",
       "      <td>524.95</td>\n",
       "      <td></td>\n",
       "      <td>34086.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-435.70</td>\n",
       "      <td>48.35</td>\n",
       "      <td>1573.90</td>\n",
       "      <td>70.89</td>\n",
       "      <td>-20.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Indiamart Inter.</td>\n",
       "      <td>4567.05</td>\n",
       "      <td>52.88</td>\n",
       "      <td>13981.83</td>\n",
       "      <td>0.04</td>\n",
       "      <td>81.60</td>\n",
       "      <td>9.83</td>\n",
       "      <td>240.20</td>\n",
       "      <td>28.18</td>\n",
       "      <td>22.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Just Dial</td>\n",
       "      <td>622.40</td>\n",
       "      <td>51.87</td>\n",
       "      <td>5247.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.32</td>\n",
       "      <td>288.45</td>\n",
       "      <td>221.37</td>\n",
       "      <td>39.32</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Nureca</td>\n",
       "      <td>380.00</td>\n",
       "      <td></td>\n",
       "      <td>380.01</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-99.38</td>\n",
       "      <td>27.84</td>\n",
       "      <td>-42.10</td>\n",
       "      <td>32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Olympia Industri</td>\n",
       "      <td>137.05</td>\n",
       "      <td>91.72</td>\n",
       "      <td>82.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>101.71</td>\n",
       "      <td>259.78</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Pace E-Commerce</td>\n",
       "      <td>23.80</td>\n",
       "      <td>99.31</td>\n",
       "      <td>53.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Citizen Infoline</td>\n",
       "      <td>32.55</td>\n",
       "      <td>195.22</td>\n",
       "      <td>17.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1.09</td>\n",
       "      <td>678.57</td>\n",
       "      <td>-8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Fone4 Communica.</td>\n",
       "      <td>6.57</td>\n",
       "      <td>41.48</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>iStreet Network</td>\n",
       "      <td>2.32</td>\n",
       "      <td></td>\n",
       "      <td>4.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-250.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>JLA Infraville</td>\n",
       "      <td>4.04</td>\n",
       "      <td>43.67</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No.              Name      CMP     P/E   Mar Cap Div Yld   NP Qtr  \\\n",
       "0     1.  Info Edg.(India)  3657.05   15.88  47243.28    0.36    93.90   \n",
       "1     2.        Zomato Ltd    48.75          41698.36    0.00    11.80   \n",
       "2     3.    FSN E-Commerce   141.75  914.42  40389.85    0.00     5.19   \n",
       "3     4.            One 97   524.95          34086.81    0.00  -435.70   \n",
       "4     5.  Indiamart Inter.  4567.05   52.88  13981.83    0.04    81.60   \n",
       "5     6.         Just Dial   622.40   51.87   5247.20    0.00    75.32   \n",
       "6     7.            Nureca   380.00            380.01    0.79     0.03   \n",
       "7     8.  Olympia Industri   137.05   91.72     82.55    0.00     0.17   \n",
       "8     9.   Pace E-Commerce    23.80   99.31     53.63    0.00            \n",
       "9    10.  Citizen Infoline    32.55  195.22     17.57    0.00     0.03   \n",
       "10   11.  Fone4 Communica.     6.57   41.48     11.20    0.00            \n",
       "11   12.   iStreet Network     2.32              4.94    0.00    -0.14   \n",
       "12   13.    JLA Infraville     4.04   43.67      2.62    0.00            \n",
       "\n",
       "   Qtr Profit Var Sales Qtr Qtr Sales Var    ROCE  \n",
       "0           59.50    604.13         65.94   24.26  \n",
       "1          103.27   1177.90         31.30  -10.62  \n",
       "2          251.28   1230.83         39.04    6.87  \n",
       "3           48.35   1573.90         70.89  -20.86  \n",
       "4            9.83    240.20         28.18   22.47  \n",
       "5          288.45    221.37         39.32   -0.49  \n",
       "6          -99.38     27.84        -42.10   32.74  \n",
       "7         1600.00    101.71        259.78    4.54  \n",
       "8                                            3.33  \n",
       "9          137.50      1.09        678.57   -8.87  \n",
       "10                                           9.90  \n",
       "11        -250.00      0.00                        \n",
       "12                                           1.27  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting that into csv file and storing it\n",
    "\n",
    "df = pd.DataFrame(table_value, columns = heading, index = None)\n",
    "market_df = df[df.astype(str)['Name']!='None']\n",
    "market_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f2a0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then form that link we are going to scrape financial data from each sector\n",
    "\n",
    "def get_topic_page(url):           \n",
    "    response = requests.get(url)    ## Pulling the request\n",
    "    if response.status_code!= 200:\n",
    "        raise Exception('Failed to load page{}'.format(url))\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')   ##parsing the data\n",
    "    return topic_doc\n",
    "\n",
    "def get_topic_title(topic_doc):\n",
    "    table = 'data-table text-nowrap striped mark-visited'       ## Getting the table tag \n",
    "    table_tag = topic_doc.find_all('table', {'class': table})   ##that contains the title\n",
    "    tr_tag =table_tag[0].find_all('tr')[0]\n",
    "    heading = []\n",
    "    for x in tr_tag.find_all('a'):\n",
    "        heading.append(x.text[:28].strip())\n",
    "    return heading\n",
    "\n",
    "def data(topic_doc):\n",
    "    table = 'data-table text-nowrap striped mark-visited'          ## Getting the table  tag\n",
    "    table_tag = topic_doc.find_all('table', {'class': table})      ## that cntains  financial ratio \n",
    "    table_value = []                                               ## of the company\n",
    "    for x in table_tag[0].find_all('tr')[1:]:\n",
    "        td_tags = x.find_all('td')\n",
    "        td_val = [y.text.strip() for y in td_tags]\n",
    "        table_value.append(td_val)\n",
    "    return pd.DataFrame(table_value, columns = heading, index = None)\n",
    "\n",
    "def scrap_topic(topic_url, topic_name):\n",
    "    topic_df = data(get_topic_page(topic_url))                      #3 saving the file as csv\n",
    "    market_df = topic_df[topic_df.astype(str)['Name']!='None']      \n",
    "    path = r'C:\\Users\\g\\Pictures\\Begining story of stock market\\ '\n",
    "    \n",
    "    market_df.to_csv(path+ topic_name +'.csv',index = None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ef4f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of repeating the process for each sector we are going to create a\n",
    "# function that pull data from csv file we are going to create\n",
    "\n",
    "# First we are going get the name of sector and link to the sector\n",
    "\n",
    "doc = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "def get_topic_title(doc):\n",
    "    selection_class = 'bordered radius-6 padding-4-12 font-size-14 ink-700'\n",
    "    topic_title  = doc.find_all('a', {'class': selection_class})\n",
    "    topic_tag = []        \n",
    "    for tag in topic_title:\n",
    "        topic_tag.append(tag.text.replace('/',\"\").strip())\n",
    "    return topic_tag \n",
    "\n",
    "def topic_url(doc):\n",
    "    selection_class = 'bordered radius-6 padding-4-12 font-size-14 ink-700'\n",
    "    topic_title  = doc.find_all('a', {'class': selection_class})\n",
    "    base = \"https://www.screener.in\"\n",
    "    topic_url = []\n",
    "    for tag in topic_title:\n",
    "        topic_url.append(base + tag['href'])\n",
    "    return topic_url\n",
    "        \n",
    "def scrape_topic():\n",
    "    url = \"https://www.screener.in/explore/\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code!= 200:\n",
    "        raise Exception('Failed to load page{}'.format(url))\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    market_data = {'title' : get_topic_title(soup), 'url': topic_url(soup)}\n",
    "    market_df = pd.DataFrame(market_data)\n",
    "    return market_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b0abdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now  we are going to  scrape the data and going to save it\n",
    "def scrape_stock_data():                     \n",
    "    print('scraping data from screener.com')       ## creating a loop to get data of all the company\n",
    "    topic_df = scrape_topic()\n",
    "    for index, row in topic_df.iterrows():\n",
    "        print('scraping top respositories for \"{}\"'.format(row['title']))\n",
    "        scrap_topic(row['url'], row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62b19bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping data from screener.com\n",
      "scraping top respositories for \"Agro Chemicals\"\n",
      "scraping top respositories for \"Air Transport Service\"\n",
      "scraping top respositories for \"Alcoholic Beverages\"\n",
      "scraping top respositories for \"Auto Ancillaries\"\n",
      "scraping top respositories for \"Automobile\"\n",
      "scraping top respositories for \"Banks\"\n",
      "scraping top respositories for \"Bearings\"\n",
      "scraping top respositories for \"Cables\"\n",
      "scraping top respositories for \"Capital Goods - Electrical Equipment\"\n",
      "scraping top respositories for \"Capital Goods-Non Electrical Equipment\"\n",
      "scraping top respositories for \"Castings, Forgings & Fastners\"\n",
      "scraping top respositories for \"Cement\"\n",
      "scraping top respositories for \"Cement - Products\"\n",
      "scraping top respositories for \"Ceramic Products\"\n",
      "scraping top respositories for \"Chemicals\"\n",
      "scraping top respositories for \"Computer Education\"\n",
      "scraping top respositories for \"Construction\"\n",
      "scraping top respositories for \"Consumer Durables\"\n",
      "scraping top respositories for \"Credit Rating Agencies\"\n",
      "scraping top respositories for \"Crude Oil & Natural Gas\"\n",
      "scraping top respositories for \"Diamond, Gems and Jewellery\"\n",
      "scraping top respositories for \"Diversified\"\n",
      "scraping top respositories for \"Dry cells\"\n",
      "scraping top respositories for \"E-CommerceApp based Aggregator\"\n",
      "scraping top respositories for \"Edible Oil\"\n",
      "scraping top respositories for \"Education\"\n",
      "scraping top respositories for \"Electronics\"\n",
      "scraping top respositories for \"Engineering\"\n",
      "scraping top respositories for \"Entertainment\"\n",
      "scraping top respositories for \"ETF\"\n",
      "scraping top respositories for \"Ferro Alloys\"\n",
      "scraping top respositories for \"Fertilizers\"\n",
      "scraping top respositories for \"Finance\"\n",
      "scraping top respositories for \"FMCG\"\n",
      "scraping top respositories for \"Gas Distribution\"\n",
      "scraping top respositories for \"Glass & Glass Products\"\n",
      "scraping top respositories for \"Healthcare\"\n",
      "scraping top respositories for \"Hotels & Restaurants\"\n",
      "scraping top respositories for \"Infrastructure Developers & Operators\"\n",
      "scraping top respositories for \"Infrastructure Investment Trusts\"\n",
      "scraping top respositories for \"Insurance\"\n",
      "scraping top respositories for \"IT - Hardware\"\n",
      "scraping top respositories for \"IT - Software\"\n",
      "scraping top respositories for \"Leather\"\n",
      "scraping top respositories for \"Logistics\"\n",
      "scraping top respositories for \"Marine Port & Services\"\n",
      "scraping top respositories for \"Media - PrintTelevisionRadio\"\n",
      "scraping top respositories for \"Mining & Mineral products\"\n",
      "scraping top respositories for \"Miscellaneous\"\n",
      "scraping top respositories for \"Non Ferrous Metals\"\n",
      "scraping top respositories for \"Oil DrillAllied\"\n",
      "scraping top respositories for \"Online Media\"\n",
      "scraping top respositories for \"Packaging\"\n",
      "scraping top respositories for \"PaintsVarnish\"\n",
      "scraping top respositories for \"Paper\"\n",
      "scraping top respositories for \"Petrochemicals\"\n",
      "scraping top respositories for \"Pharmaceuticals\"\n",
      "scraping top respositories for \"Plantation & Plantation Products\"\n",
      "scraping top respositories for \"Plastic products\"\n",
      "scraping top respositories for \"Power Generation & Distribution\"\n",
      "scraping top respositories for \"Power Infrastructure\"\n",
      "scraping top respositories for \"Printing & Stationery\"\n",
      "scraping top respositories for \"Quick Service Restaurant\"\n",
      "scraping top respositories for \"Railways\"\n",
      "scraping top respositories for \"Readymade Garments Apparells\"\n",
      "scraping top respositories for \"Real Estate Investment Trusts\"\n",
      "scraping top respositories for \"Realty\"\n",
      "scraping top respositories for \"Refineries\"\n",
      "scraping top respositories for \"Refractories\"\n",
      "scraping top respositories for \"Retail\"\n",
      "scraping top respositories for \"Sanitaryware\"\n",
      "scraping top respositories for \"Ship Building\"\n",
      "scraping top respositories for \"Shipping\"\n",
      "scraping top respositories for \"Steel\"\n",
      "scraping top respositories for \"Stock Commodity Brokers\"\n",
      "scraping top respositories for \"Sugar\"\n",
      "scraping top respositories for \"Telecom-HandsetsMobile\"\n",
      "scraping top respositories for \"Telecomm Equipment & Infra Services\"\n",
      "scraping top respositories for \"Telecomm-Service\"\n",
      "scraping top respositories for \"Textiles\"\n",
      "scraping top respositories for \"Tobacco Products\"\n",
      "scraping top respositories for \"Trading\"\n",
      "scraping top respositories for \"Tyres\"\n"
     ]
    }
   ],
   "source": [
    "scrape_stock_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ffe92a",
   "metadata": {},
   "source": [
    "![](https://imgur.com/A8ZeUan.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db1054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdd902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
